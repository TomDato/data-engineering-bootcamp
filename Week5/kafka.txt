# Preparations

### Container initialization

docker-compose up -d
docker ps --format "{{.ID}}\t{{.Names}}\t{{.Status}}"


# QUESTIONS
## 1.
Create a topic named `atscale`, 2 partitions and replication factor 1.

docker exec -it kafka1 bash

/kafka/bin/kafka-topics.sh \
--bootstrap-server localhost:9092 \
--create --topic atscale \
--partitions 2 \
--replication-factor 1

## 2. 
List all topics.

/kafka/bin/kafka-topics.sh \
--bootstrap-server localhost:9092 \
--list

## 3. 
Describe `atscale` topic.

/kafka/bin/kafka-topics.sh \
--bootstrap-server localhost:9092 \
--describe --topic atscale

## 4. 
Use data-generator and send `https://raw.githubusercontent.com/erkansirin78/datasets/master/Churn_Modelling.csv` to  3 partitioned `churn` topic.

- Message key should be CustomerId.

- Consume under `churn_group` and this group must have 3 consumer. 
    - Use different terminal for each consumer. 
    - Use `kafka-console-consumer.sh` as a consumer.

### Topic
/kafka/bin/kafka-topics.sh \
--bootstrap-server localhost:9092 \
--create --topic churn \
--partitions 3 \

### Consumer (3x)
docker exec -it kafka1 bash

/kafka/bin/kafka-console-consumer.sh \
--bootstrap-server localhost:9092 \
--topic churn \
--group churn_group \
--property print.partition=true \
--property print.key=true

### Producer
cd data-generator/
python3 -m pip install pip --upgrade
pip install -r requirements.txt

python3 dataframe_to_kafka.py \
-t churn \
-i "https://raw.githubusercontent.com/erkansirin78/datasets/master/Churn_Modelling.csv" \
-k 1 \
-e csv \
-s ',' \
-b localhost:9092 \
-shf true

#### Refer kafka_churn_streaming.png for result of upper command.

## 5. 
Delete `atscale` and `churn` topics.

/kafka/bin/kafka-topics.sh \
--bootstrap-server localhost:9092 \
--delete --topic atscale

/kafka/bin/kafka-topics.sh \
--bootstrap-server localhost:9092 \
--delete --topic churn
